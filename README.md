# ğŸ§  CLONE: í–‰ë™ ê¸°ë°˜ ë¬´ì˜ì‹ ì„ í˜¸ë„ ë¶„ì„ ì‹œìŠ¤í…œ
> **Behavior-based Subconscious Preference Analysis System**
>
> *"ë‹¹ì‹ ì´ í™•ì‹ í•˜ì§€ ëª» í•˜ëŠ” ì„ íƒì§€, ë‹¹ì‹ ì˜ ë™ê³µê³¼ ìì„¸ë¡œ ê³¨ë¼ë´…ì‹œë‹¤."*

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Gemini API](https://img.shields.io/badge/AI-Gemini%202.5%20Flash-8E75B2?style=for-the-badge&logo=google&logoColor=white)](https://aistudio.google.com/)
[![OpenCV](https://img.shields.io/badge/Vision-OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)](LICENSE)

<img src="figure/main.PNG" width="800" alt="CLONE Main GUI">

</div>

## ğŸ“º í”„ë¡œì íŠ¸ ì‹œì—° (Demo)

**CLONE framework ê¸°ë²•ì„ ì ìš©í•œ LLM ì‹œìŠ¤í…œ**ì´ ì‚¬ìš©ìì˜ ìƒí™©ì„ ë¶„ì„í•˜ê³ , ì‹œì„ ê³¼ ìì„¸ë¥¼ ì¶”ì í•˜ì—¬ ìµœì ì˜ ì„ íƒì§€ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ì²´ ê³¼ì •ì…ë‹ˆë‹¤.

<div align="center">
  <video src="figure/vid.mp4" width="800" controls="controls"></video>
  <br>
  <em>(ìœ„ ì˜ìƒì´ ì¬ìƒë˜ì§€ ì•Šì„ ê²½ìš°, figure/vid.mp4 íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.)</em>
</div>

---

## ğŸ“– í”„ë¡œì íŠ¸ ì†Œê°œ (Overview)

**"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì§€?", "ì´ë²ˆ ì£¼ë§ì— ë­ í•˜ì§€?"**
ìš°ë¦¬ëŠ” ë§¤ì¼ ìˆ˜ë§ì€ ì„ íƒì˜ ê¸°ë¡œì— ì„œì§€ë§Œ, ìŠ¤ìŠ¤ë¡œê°€ ì§„ì§œ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ ëª¨ë¥´ëŠ” **'ì„ íƒ ì¥ì• (Decision Paralysis)'**ë¥¼ ê²ªìŠµë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìê°€ ì„ íƒì§€ë¥¼ ì½ëŠ” ë™ì•ˆì˜ **ë¹„ì–¸ì–´ì  í–‰ë™(ì‹œì„ , ìì„¸, ë¯¸ì„¸ í‘œì •)**ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì‚¬ìš©ìì˜ ë¬´ì˜ì‹ì  ì„ í˜¸ë„ë¥¼ íŒŒì•…í•˜ê³  ìµœì ì˜ ì„ íƒì§€ë¥¼ ì¶”ì²œí•´ì£¼ëŠ” **AI ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.

ìµœì‹  LLM í”„ë¡¬í”„íŒ… ê´€ë ¨ ì—°êµ¬ì¸ **CLONE: Synthetic Guideline-based Clinical Reasoning with Large Language Models for Early Diagnosis of Mild Cognitive Impairment.** í”„ë ˆì„ì›Œí¬[1]ë¥¼ ì‘ìš©í•˜ì—¬, ë‹¨ìˆœ í†µê³„ê°€ ì•„ë‹Œ **'ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ AI ì—ì´ì „íŠ¸'**ê°€ í–‰ë™ ë°ì´í„°ë¥¼ í•´ì„í•˜ê³  ë…¼ë¦¬ì ì¸ ì¶”ì²œ ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ëª©í‘œ
* **Context-Aware Curation:** ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©(ë§¥ë½)ì— ë§ì¶° ì„ íƒì§€ì˜ ì¥ë‹¨ì ì„ ì„¤ë“ë ¥ ìˆê²Œ ì„¤ëª…
* **Behavior Tracking:** ì›¹ìº ì„ í†µí•´ Gaze(ì‹œì„ ), Posture(ìì„¸), Micro-expression(ë¯¸ì„¸ í‘œì •)ì„ ì‹¤ì‹œê°„ ì¶”ì 
* **Expert Reasoning:** í–‰ë™ ì‹¬ë¦¬í•™ìì˜ ì§„ë‹¨ ê°€ì´ë“œë¼ì¸ì„ í•™ìŠµí•œ AIê°€ ë°ì´í„°ë¥¼ í•´ì„í•˜ì—¬ ìµœì¢… ì˜ì‚¬ê²°ì • ì§€ì›

---

## âš™ï¸ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ (Pipeline)

ë³¸ ì‹œìŠ¤í…œì€ **ì…ë ¥ -> ì¸¡ì • -> ë¶„ì„ -> ê²°ê³¼**ì˜ 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

| ë‹¨ê³„ | ì„¤ëª… | ì‹¤í–‰ í™”ë©´ |
| :--- | :--- | :--- |
| **Step 1.<br>Context Input** | **ì‚¬ìš©ì ìƒí™© ì…ë ¥**<br>ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©(ì˜ˆ: "ëˆì´ ë¶€ì¡±í•´")ê³¼ ê³ ë¯¼ ì¤‘ì¸ ì„ íƒì§€ë“¤ì„ ì…ë ¥ë°›ìŠµë‹ˆë‹¤. LLMì´ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤. | <img src="figure/mainCLI.PNG" width="400" alt="Input CLI"> |
| **Step 2.<br>Measurement** | **ì‹¤ì‹œê°„ ë°˜ì‘ ì¸¡ì •**<br>ì‚¬ìš©ìê°€ í™”ë©´ì˜ í…ìŠ¤íŠ¸ë¥¼ ì½ëŠ” ë™ì•ˆ ì›¹ìº ì´ `Leaning(ê¸°ìš¸ê¸°)`, `Gaze(ì‹œì„ )`, `Emotion(ê°ì •)`ì„ ì´ˆë‹¨ìœ„ë¡œ ë¡œê¹…í•©ë‹ˆë‹¤. | <img src="figure/main.PNG" width="400" alt="Measurement GUI"> |
| **Step 3.<br>Data Analysis** | **í–‰ë™ ë°ì´í„° ë¶„ì„**<br>ìˆ˜ì§‘ëœ Log Data(CSV)ë¥¼ ë¶„ì„í•˜ì—¬ `High Engagement`, `Confusion` ë“±ì˜ ì˜ë¯¸ ìˆëŠ” í–‰ë™ ì§€í‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤. | <img src="figure/mainresult.PNG" width="400" alt="Analysis Result"> |
| **Step 4.<br>AI Judgment** | **ìµœì¢… ì¶”ì²œ**<br>ì‚¬ì „ì— í•™ìŠµëœ **í–‰ë™ ë¶„ì„ ê°€ì´ë“œë¼ì¸**ì„ ê¸°ë°˜ìœ¼ë¡œ, Judge Agentê°€ ê°€ì¥ ì„ í˜¸ë„ê°€ ë†’ì€ ì„ íƒì§€ë¥¼ ì¶”ì²œí•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. | *(ìœ„ ê²°ê³¼ í™”ë©´ í•˜ë‹¨ ì°¸ì¡°)* |

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)

| Category | Technology | Version | Description |
| :--- | :--- | :--- | :--- |
| **Language** | ![Python](https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white) | 3.10.19 | ì „ì²´ ì‹œìŠ¤í…œ ë¡œì§ êµ¬í˜„ |
| **AI Core** | ![Gemini](https://img.shields.io/badge/-Google%20Gemini-8E75B2?logo=google&logoColor=white) | 2.5 Flash | ìê·¹ ìƒì„±, í–‰ë™ ë°ì´í„° í•´ì„, ê°€ì´ë“œë¼ì¸ í•©ì„± |
| **Vision** | ![OpenCV](https://img.shields.io/badge/-OpenCV-5C3EE8?logo=opencv&logoColor=white) | 4.11.0 | ì›¹ìº  ì œì–´ ë° ì´ë¯¸ì§€ ì²˜ë¦¬ |
| **Pose/Face** | ![MediaPipe](https://img.shields.io/badge/-MediaPipe-00BACC?logo=google&logoColor=white) | 0.10.21 | ì‹¤ì‹œê°„ ìì„¸(Pose) ë° ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ |
| **Emotion** | **EmotiEffLib** | 1.1.1 | EfficientNet ê¸°ë°˜ ì‹¤ì‹œê°„ í‘œì • ì¸ì‹ |
| **Data** | ![Pandas](https://img.shields.io/badge/-Pandas-150458?logo=pandas&logoColor=white) | 2.3.3 | í–‰ë™ ë¡œê·¸ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ |

---

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰ (Getting Started)

### 1. í™˜ê²½ ì„¤ì • (Installation)
í”„ë¡œì íŠ¸ë¥¼ í´ë¡ í•˜ê³  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

# Repository Clone
git clone [https://github.com/zion2200/OSS_termproject_final.git](https://github.com/zion2200/OSS_termproject_final.git)
cd OSS_termproject_final

# Install Dependencies
pip install -r requirements.txt

### 2. API í‚¤ ì„¤ì • (Configuration)
`config.py` íŒŒì¼ì„ ì—´ì–´ Google Gemini API í‚¤ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
*(ì£¼ì˜: API í‚¤ëŠ” GitHubì— ì ˆëŒ€ ì—…ë¡œë“œí•˜ì§€ ë§ˆì„¸ìš”.)*

API KEY ì§ì ‘ ì…ë ¥ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
`GEMINI_API_KEY = "YOUR_ACTUAL_API_KEY_HERE"`


### 3. ì‹¤í–‰ (Run)
ë©”ì¸ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ì—¬ ì‹¤í—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.
`bash
python main.py
`

---

## ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)

```text
ğŸ“¦ OSS_termproject_final
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“‚ logs                # ì›¹ìº ìœ¼ë¡œ ìˆ˜ì§‘ëœ Raw CSV ë°ì´í„°
 â”ƒ â”— ğŸ“‚ seeds               # ì „ì²˜ë¦¬ ë° ë¶„ì„ëœ JSON í–‰ë™ ë°ì´í„°
 â”£ ğŸ“‚ figure                # README ë° ì‹œì—°ìš© ì´ë¯¸ì§€/ì˜ìƒ
 â”£ ğŸ“‚ modules               # í•µì‹¬ ê¸°ëŠ¥ ëª¨ë“ˆ
 â”ƒ â”£ ğŸ“œ stimulus.py         # LLM íë ˆì´í„° (ìê·¹ ìƒì„±)
 â”ƒ â”£ ğŸ“œ recorder.py         # OpenCV/MediaPipe ë…¹í™”ê¸°
 â”ƒ â”£ ğŸ“œ preprocessor.py     # ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ
 â”ƒ â”£ ğŸ“œ guideline_maker.py  # ê°€ì´ë“œë¼ì¸ ìƒì„±ê¸° (Stage 2)
 â”ƒ â”— ğŸ“œ judge.py            # íŒì‚¬ ì—ì´ì „íŠ¸ (Stage 3)
 â”£ ğŸ“œ main.py               # [ë©”ì¸] í”„ë¡œê·¸ë¨ ì‹¤í–‰ íŒŒì¼
 â”£ ğŸ“œ stage2_make_guideline.py # [ê´€ë¦¬ììš©] ê°€ì´ë“œë¼ì¸ í•™ìŠµ ë„êµ¬
 â”£ ğŸ“œ stage3_inference.py   # [ê°œë³„ì‹¤í–‰] ì¶”ë¡  ë„êµ¬
 â”£ ğŸ“œ guideline.md          # ìƒì„±ëœ í–‰ë™ ë¶„ì„ ê°€ì´ë“œë¼ì¸
 â”£ ğŸ“œ config.py             # ì„¤ì • íŒŒì¼
 â”£ ğŸ“œ requirements.txt      # ì˜ì¡´ì„± ëª©ë¡
 â”— ğŸ“œ README.md             # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
```
 ---

### **[Part 3] ë¼ì´ì„ ìŠ¤ ë° ì°¸ê³ ë¬¸í—Œ**

```markdown
---

## âš–ï¸ ë¼ì´ì„ ìŠ¤ ë° ì°¸ê³ ë¬¸í—Œ (License & References)

### License
ì´ í”„ë¡œì íŠ¸ëŠ” **MIT License**ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.

### References & Acknowledgements
ë³¸ í”„ë¡œì íŠ¸ëŠ” ì•„ë˜ ë…¼ë¬¸ì˜ ë°©ë²•ë¡ ì„ ì°¸ì¡° ë° ì‘ìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

* **[1]** Cha, S., Park, J., Choi, H., Ryu, H., & Seo, K. (2025, April). **CLONE: Synthetic Guideline-based Clinical Reasoning with Large Language Models for Early Diagnosis of Mild Cognitive Impairment.** *In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (pp. 1-14).*
* **[2]** Shimojo, S., Simion, C., Shimojo, E., & Scheier, C. (2003). **Gaze bias both reflects and influences preference.** *Nature neuroscience, 6(12), 1317-1322.*
* **[3]** Wedel, M., Pieters, R., & van der Lans, R. (2023). **Modeling eye movements during decision making: A review.** *Psychometrika, 88(2), 697-729.*
* **[4]** Ting, C. C., & Gluth, S. (2024). **Unraveling information processes of decision-making with eye-tracking data.** *Frontiers in Behavioral Economics, 3, 1384713.*

#### Libraries
* **EmotiEffLib:** [https://github.com/monde-s/EmotiEffLib](https://github.com/monde-s/EmotiEffLib) - Efficient facial emotion recognition.
* **Google Generative AI SDK:** [https://pypi.org/project/google-generativeai/](https://pypi.org/project/google-generativeai/)

---

### ğŸ‘¨â€ğŸ’» Contributors
* **zion2200** - *Main Developer & Researcher*
* *(2025-2 Open Source Software Term Project)*