
import os
import json
import glob
import google.generativeai as genai
from config import GEMINI_API_KEY, SEED_DIR

# ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
MODEL_NAME = "gemini-2.5-flash"

SYSTEM_PROMPT = """
You are a senior Behavioral Psychologist. 
Your task is to write a "Ground Truth Analysis" based on the Subject's self-reported preference and their observed non-verbal behavior.

INPUT:
1. Observed Behavior: (Posture, Gaze, Emotions detected by AI)
2. Subject's Actual Preference: (Score 1-5 and their comment)

OUTPUT:
Write a professional, 3-4 sentence analysis in KOREAN.
- Connect the observed behavior to the actual preference.
- If the behavior matched the preference (e.g., liked it + nodded), explain it as a strong signal.
- If there was a discrepancy (e.g., liked it + frowned), interpret it carefully (e.g., "Despite the serious expression indicating concentration...").
- Tone: Clinical, Objective, Insightful.
"""

def generate_expert_analysis(seed_data, user_score, user_comment):
    # LLMì—ê²Œ ì¤„ ë¬¸ë§¥ êµ¬ì„±
    behavior_summary = seed_data.get('rule_based_interpretation', 'No behavioral data')
    metrics = seed_data.get('behavior_metrics', {})
    
    prompt = f"""
    ### Content Info
    Option: {seed_data['stimulus_content']['title']}
    
    ### Observed Behavior (AI detected)
    - Summary: {behavior_summary}
    - Key Metrics: {json.dumps(metrics, indent=2)}
    
    ### Subject's Self-Report (Ground Truth)
    - Preference Score: {user_score} / 5  (1=Hate, 5=Love)
    - Subject's Comment: "{user_comment}"
    
    Based on this, write the 'expert_analysis' paragraph.
    """
    
    model = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=SYSTEM_PROMPT)
    
    try:
        res = model.generate_content(prompt)
        return res.text.strip()
    except Exception as e:
        print(f"[ERROR] LLM generation failed: {e}")
        return "ë¶„ì„ ìƒì„± ì‹¤íŒ¨"

def main():
    files = sorted(glob.glob(os.path.join(SEED_DIR, "*.json")))
    print(f"=== Expert Labeling Tool (Total {len(files)} files) ===")
    print("ë³¸ì¸ì´ ëŠê¼ˆë˜ ì‹¤ì œ ì„ í˜¸ë„ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. AIê°€ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì§€ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n")

    for idx, fpath in enumerate(files):
        with open(fpath, "r", encoding="utf-8") as f:
            data = json.load(f)

        # ì´ë¯¸ ë¶„ì„ì´ ìˆìœ¼ë©´ ìŠ¤í‚µí• ì§€ ë¬¼ì–´ë³´ê¸° (ì—¬ê¸°ì„  ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ì§„í–‰)
        if data.get("expert_analysis"):
            print(f"âš ï¸ ì´ë¯¸ ë¶„ì„ëœ íŒŒì¼ì…ë‹ˆë‹¤: {os.path.basename(fpath)}")
            continue # ìŠ¤í‚µí•˜ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ

        print(f"\n[{idx+1}/{len(files)}] {os.path.basename(fpath)}")
        print(f"ì œëª©: {data['stimulus_content']['title']}")
        print(f"ìš”ì•½: {data['stimulus_content']['summary']}")
        print(f"í–‰ë™ ìš”ì•½: {data.get('rule_based_interpretation', 'N/A')}")
        print("-" * 30)

        # ì‚¬ìš©ì ì…ë ¥ (Ground Truth ì£¼ì…)
        while True:
            try:
                score = int(input("Q1. ì‹¤ì œ ì´ ì„ íƒì§€ê°€ ì–¼ë§ˆë‚˜ ë§˜ì— ë“œì…¨ë‚˜ìš”? (1~5): "))
                if 1 <= score <= 5: break
            except: pass
            print("1ì—ì„œ 5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
        comment = input("Q2. ê°„ë‹¨í•œ ì´ìœ ë‚˜ ë‹¹ì‹œ ê¸°ë¶„ì€? (ì„ íƒ/ì—”í„°): ").strip()
        if not comment: comment = "ë³„ë‹¤ë¥¸ ì´ìœ  ì—†ìŒ."

        print("ğŸ”„ AIê°€ ì „ë¬¸ê°€ ì†Œê²¬ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...")
        expert_text = generate_expert_analysis(data, score, comment)
        
        # ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
        print(f"\n[ì‘ì„±ëœ ë¶„ì„]\n{expert_text}")
        
        # ë°ì´í„° ì—…ë°ì´íŠ¸
        data['expert_analysis'] = expert_text
        data['ground_truth_preference'] = score # ë‚˜ì¤‘ì— ì •í™•ë„ ì¸¡ì •ìš©ìœ¼ë¡œ ì €ì¥í•´ë‘ë©´ ì¢‹ìŒ
        
        with open(fpath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print("âœ… ì €ì¥ ì™„ë£Œ!")

    print("\n=== ëª¨ë“  ë¼ë²¨ë§ ì‘ì—… ì™„ë£Œ ===")

if __name__ == "__main__":
    main()